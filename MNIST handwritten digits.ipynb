{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8b27bb",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80beea2",
   "metadata": {},
   "source": [
    "Classifying handwritten digits using a neural network in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb308a",
   "metadata": {},
   "source": [
    "Following the pytorch tutorials at https://pytorch.org/tutorials/beginner/basics/intro.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6ac2a",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf0623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions and classes\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a235b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Download and/or load dataset (thanks Yann), and transform to tensors, and one-hot encodings\n",
    "target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "train = MNIST(root=\"data\", transform=ToTensor(), target_transform=target_transform, download=True)\n",
    "test = MNIST(root=\"data\", transform=ToTensor(), target_transform=target_transform, download=True)\n",
    "\n",
    "# Make dataloaders\n",
    "train_dataloader = DataLoader(train, batch_size=64)\n",
    "test_dataloader = DataLoader(test, batch_size=64)\n",
    "\n",
    "# Enumerate training dataloader\n",
    "examples = enumerate(train_dataloader)\n",
    "\n",
    "# Get first batch of samples and check shape\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509ad833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few inputs and labels\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i in range(3):\n",
    "    ax = [ax1, ax2, ax3][i]\n",
    "    ax.imshow(example_data[i][0])\n",
    "    ax.set_title(f\"{example_targets[i].argmax(0)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404674bf",
   "metadata": {},
   "source": [
    "## Feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b87cbfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 28, 28])\n",
      "Flattened: torch.Size([1, 784])\n",
      "Linear: tensor([[-0.2457, -0.1441, -0.1078,  0.2326]], grad_fn=<AddmmBackward0>)\n",
      "ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.2326]], grad_fn=<ReluBackward0>)\n",
      "Model: tensor([[ 0.2443,  0.4510,  0.1096, -0.0489]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.2598, 0.3194, 0.2270, 0.1938]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# Breakdown modelling functions\n",
    "X = torch.rand(1, 28, 28)\n",
    "print(f\"Input: {X.shape}\")\n",
    "X_flat = nn.Flatten()(X)\n",
    "print(f\"Flattened: {X_flat.shape}\")\n",
    "X_l = nn.Linear(28*28, 4)(X_flat)\n",
    "print(f\"Linear: {X_l}\")\n",
    "X_r = nn.ReLU()(X_l)\n",
    "print(f\"ReLU: {X_r}\")\n",
    "logits = nn.Linear(4, 4)(X_r)\n",
    "print(f\"Model: {logits}\")\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "print(f\"Probabilities: {pred_probab}\")\n",
    "print(f\"Predicted class: {pred_probab.argmax(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a8008a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0478,  0.0041,  0.0234, -0.0700, -0.0953,  0.0914,  0.0948, -0.0567,\n",
       "          0.1128,  0.1416]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a neural network\n",
    "ff_seq = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10),\n",
    ")\n",
    "ff_seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cf396b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network model class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, seq_modules):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.seq_modules = seq_modules\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.seq_modules(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d558ec3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (seq_modules): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model\n",
    "ff_model = NeuralNetwork(ff_seq)\n",
    "print(ff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b67daf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_modules.1.weight\n",
      "Size: torch.Size([512, 784])\n",
      "Values : tensor([[ 1.0193e-03,  2.9743e-02,  6.9053e-03,  ..., -2.6484e-02,\n",
      "          2.1244e-02, -9.8113e-05],\n",
      "        [-4.2283e-03,  2.0192e-02, -2.0636e-02,  ...,  2.3132e-02,\n",
      "         -2.2456e-02,  1.5960e-02]], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "name, param = next(ff_model.named_parameters())\n",
    "print(f\"Layer: {name}\")\n",
    "print(f\"Size: {param.size()}\")\n",
    "print(f\"Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a50e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0478,  0.0041,  0.0234, -0.0700, -0.0953,  0.0914,  0.0948, -0.0567,\n",
       "          0.1128,  0.1416]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use model to get predictions\n",
    "ff_model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d34a6",
   "metadata": {},
   "source": [
    "## Move model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54f1c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU or CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59265cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network model\n",
    "ff_model = ff_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d1889b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: tensor([[ 0.0795, -0.0484,  0.0224, -0.0457, -0.0652,  0.0321,  0.0637, -0.0574,\n",
      "          0.1391,  0.1909]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use model to get predictions on GPU\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "print(f\"Model: {ff_model(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06de20b",
   "metadata": {},
   "source": [
    "## Define training/validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f72b5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.to(device)\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4228b22",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6afc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(ff_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8371b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298903  [    0/60000]\n",
      "loss: 2.297168  [ 6400/60000]\n",
      "loss: 2.292222  [12800/60000]\n",
      "loss: 2.276720  [19200/60000]\n",
      "loss: 2.277781  [25600/60000]\n",
      "loss: 2.275098  [32000/60000]\n",
      "loss: 2.268406  [38400/60000]\n",
      "loss: 2.271690  [44800/60000]\n",
      "loss: 2.255951  [51200/60000]\n",
      "loss: 2.244268  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 2.249767 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.244042  [    0/60000]\n",
      "loss: 2.238919  [ 6400/60000]\n",
      "loss: 2.248145  [12800/60000]\n",
      "loss: 2.206284  [19200/60000]\n",
      "loss: 2.223179  [25600/60000]\n",
      "loss: 2.220074  [32000/60000]\n",
      "loss: 2.196941  [38400/60000]\n",
      "loss: 2.220773  [44800/60000]\n",
      "loss: 2.185590  [51200/60000]\n",
      "loss: 2.162479  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 2.175430 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.165941  [    0/60000]\n",
      "loss: 2.153985  [ 6400/60000]\n",
      "loss: 2.180377  [12800/60000]\n",
      "loss: 2.099205  [19200/60000]\n",
      "loss: 2.137998  [25600/60000]\n",
      "loss: 2.131625  [32000/60000]\n",
      "loss: 2.083193  [38400/60000]\n",
      "loss: 2.132727  [44800/60000]\n",
      "loss: 2.070579  [51200/60000]\n",
      "loss: 2.028225  [57600/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17564/3670835137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mff_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mff_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlast_correct\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17564/4121730871.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_correct = 0\n",
    "for t in range(10):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, ff_model, loss_fn, optimizer)\n",
    "    correct = test_loop(test_dataloader, ff_model, loss_fn)\n",
    "    if correct - last_correct < 0.01:\n",
    "        break\n",
    "    else:\n",
    "        last_correct = correct\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66898159",
   "metadata": {},
   "source": [
    "## Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/ff_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/ff_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cc36c",
   "metadata": {},
   "source": [
    "## Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9883cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few sample inputs and predictions\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i in range(3):\n",
    "    ax = [ax1, ax2, ax3][i]\n",
    "    ax.imshow(example_data[i][0])\n",
    "    ax.set_title(f\"{ff_model(example_data[i].to(device)).argmax(1)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce121b8e",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e61b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b520617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0082,  0.0921, -0.1635, -0.1004,  0.1426,  0.0284, -0.1454, -0.1945,\n",
       "          0.1260,  0.1891]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a neural network\n",
    "conv_seq = nn.Sequential(\n",
    "    nn.Conv2d(1, 5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(5*24*24, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10),\n",
    ")\n",
    "conv_seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be065e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=2880, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create neural network model\n",
    "conv_model = NeuralNetwork(conv_seq).to(device)\n",
    "print(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44b68b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0082,  0.0921, -0.1635, -0.1004,  0.1426,  0.0284, -0.1454, -0.1945,\n",
       "          0.1260,  0.1891]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use model to get predictions\n",
    "conv_model(X.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de7362c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(conv_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32ccc286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.873989  [    0/60000]\n",
      "loss: 1.673955  [ 6400/60000]\n",
      "loss: 1.683701  [12800/60000]\n",
      "loss: 1.427447  [19200/60000]\n",
      "loss: 1.382346  [25600/60000]\n",
      "loss: 1.242085  [32000/60000]\n",
      "loss: 1.059656  [38400/60000]\n",
      "loss: 1.176145  [44800/60000]\n",
      "loss: 0.945284  [51200/60000]\n",
      "loss: 0.848434  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.821153 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.896722  [    0/60000]\n",
      "loss: 0.645473  [ 6400/60000]\n",
      "loss: 0.743575  [12800/60000]\n",
      "loss: 0.624107  [19200/60000]\n",
      "loss: 0.612872  [25600/60000]\n",
      "loss: 0.583204  [32000/60000]\n",
      "loss: 0.507099  [38400/60000]\n",
      "loss: 0.681044  [44800/60000]\n",
      "loss: 0.582747  [51200/60000]\n",
      "loss: 0.545725  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.517669 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.579410  [    0/60000]\n",
      "loss: 0.418876  [ 6400/60000]\n",
      "loss: 0.459973  [12800/60000]\n",
      "loss: 0.470456  [19200/60000]\n",
      "loss: 0.442511  [25600/60000]\n",
      "loss: 0.442578  [32000/60000]\n",
      "loss: 0.362574  [38400/60000]\n",
      "loss: 0.550823  [44800/60000]\n",
      "loss: 0.473609  [51200/60000]\n",
      "loss: 0.476575  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.432288 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.475563  [    0/60000]\n",
      "loss: 0.356879  [ 6400/60000]\n",
      "loss: 0.358348  [12800/60000]\n",
      "loss: 0.425292  [19200/60000]\n",
      "loss: 0.380712  [25600/60000]\n",
      "loss: 0.393872  [32000/60000]\n",
      "loss: 0.302771  [38400/60000]\n",
      "loss: 0.500234  [44800/60000]\n",
      "loss: 0.419470  [51200/60000]\n",
      "loss: 0.452747  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.393294 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "last_correct = 0\n",
    "for t in range(10):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, conv_model, loss_fn, optimizer)\n",
    "    correct = test_loop(test_dataloader, conv_model, loss_fn)\n",
    "    if correct - last_correct < 0.01:\n",
    "        break\n",
    "    else:\n",
    "        last_correct = correct\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc16b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
